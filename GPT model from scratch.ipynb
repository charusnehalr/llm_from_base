{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148349d0-5b62-4561-aeb3-42efa9def899",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1232199-c090-4c5c-9c05-5e3eca9a89dc",
   "metadata": {},
   "source": [
    "# GPT architecture part 1: Dummy GPT model class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff43a05-5fcf-483f-9f36-8330e8628ecc",
   "metadata": {},
   "source": [
    "- Step 1: Use a placeholder for TransformerBlock\n",
    "- Step 2: Use a placeholder for LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97006581-e54c-45f6-b0f8-263e35e6427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "                )\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24b081-01e2-4379-82b5-13bdf9750169",
   "metadata": {},
   "source": [
    "- The DummyGPTModel class in this code defines a simplified version of a GPT-like model using\n",
    "PyTorch's neural network module (nn.Module). \n",
    "- The model architecture in the\n",
    "DummyGPTModel class consists of token and positional embeddings, dropout, a series of\n",
    "transformer blocks (DummyTransformerBlock), a final layer normalization\n",
    "(DummyLayerNorm), and a linear output layer (out_head). \n",
    "- The configuration is passed in via\n",
    "a Python dictionary, for instance, the GPT_CONFIG_124M dictionary we created earlier.\n",
    "\n",
    "- The forward method describes the data flow through the model: it computes token and\n",
    "positional embeddings for the input indices, applies dropout, processes the data through\n",
    "the transformer blocks, applies normalization, and finally produces logits with the linear\n",
    "output layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582ce9c-3ab8-4085-9865-e3d443797cdf",
   "metadata": {},
   "source": [
    "# Step 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111c4ee7-0ec4-4ea8-8718-158ccc1e1b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fdd20e-1413-4680-894e-420817f1c47c",
   "metadata": {},
   "source": [
    "# Create an instance of DummyGPTmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37fdf857-a394-4e63-8182-47c83a27beca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa9203-734c-4794-ae8d-b26b1ae2780e",
   "metadata": {},
   "source": [
    "- The output tensor has two rows corresponding to the two text samples. Each text sample\n",
    "consists of 4 tokens; each token is a 50,257-dimensional vector, which matches the size of\n",
    "the tokenizer's vocabulary.\n",
    "- The embedding has 50,257 dimensions because each of these dimensions refers to a\n",
    "unique token in the vocabulary. At the end of this chapter, when we implement the\n",
    "postprocessing code, we will convert these 50,257-dimensional vectors back into token IDs,\n",
    "which we can then decode into words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c6836-a411-499d-8bfc-436cca752e3f",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 2: LAYER NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8b728b-fb3d-4536-957b-ad8417b24b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) #A\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6337f7-1d6e-442e-a36d-4ad1f83879af",
   "metadata": {},
   "source": [
    "- The neural network layer we have coded consists of a Linear layer followed by a non-linear\n",
    "activation function, ReLU (short for Rectified Linear Unit), which is a standard activation\n",
    "function in neural networks. \n",
    "- If you are unfamiliar with ReLU, it simply thresholds negative\n",
    "inputs to 0, ensuring that a layer outputs only positive values, which explains why the\n",
    "resulting layer output does not contain any negative values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5796258-be00-4d98-92bd-cc7eccac24ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9ffc3-68f6-4aeb-a64e-f57d1058d28a",
   "metadata": {},
   "source": [
    "- The first row in the mean tensor above contains the mean value for the first input row, and\n",
    "the second output row contains the mean for the second input row.\n",
    "- Using keepdim=True in operations like mean or variance calculation ensures that the\n",
    "output tensor retains the same number of dimensions as the input tensor, even though the\n",
    "operation reduces the tensor along the dimension specified via dim. \n",
    "- For instance, without\n",
    "keepdim=True, the returned mean tensor would be a 2-dimensional vector [0.1324,\n",
    "0.2170] instead of a 2×1-dimensional matrix [[0.1324], [0.2170]].\n",
    "- For a 2D tensor (like a matrix), using dim=-1 for operations such as\n",
    "mean or variance calculation is the same as using dim=1. \n",
    "- This is because -1 refers to the\n",
    "tensor's last dimension, which corresponds to the columns in a 2D tensor. \n",
    "- Later, when\n",
    "adding layer normalization to the GPT model, which produces 3D tensors with shape\n",
    "[batch_size, num_tokens, embedding_size], we can still use dim=-1 for normalization\n",
    "across the last dimension, avoiding a change from dim=1 to dim=2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93d499-0653-44cb-9038-c36a957d1977",
   "metadata": {},
   "source": [
    "- Next, let us apply layer normalization to the layer outputs we obtained earlier. The\n",
    "operation consists of subtracting the mean and dividing by the square root of the variance\n",
    "(also known as standard deviation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400c6c2d-1266-47a2-9c31-aa1c127a2d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db990bdf-269d-4018-8f16-c797612fbf3a",
   "metadata": {},
   "source": [
    "- Note that the value 2.9802e-08 in the output tensor is the scientific notation for 2.9802 ×\n",
    "10-8, which is 0.0000000298 in decimal form. This value is very close to 0, but it is not\n",
    "exactly 0 due to small numerical errors that can accumulate because of the finite precision\n",
    "with which computers represent numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb430679-6e2a-4136-83e1-f922a49128d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.0000],\n",
      "        [0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6501ed2f-383e-45ce-aabd-bc5bf986d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a30ac-75c2-471c-96b9-710a5d144d35",
   "metadata": {},
   "source": [
    "- This specific implementation of layer Normalization operates on the last dimension of the\n",
    "input tensor x, which represents the embedding dimension (emb_dim). \n",
    "- The variable eps is a\n",
    "small constant (epsilon) added to the variance to prevent division by zero during\n",
    "normalization. \n",
    "- The scale and shift are two trainable parameters (of the same dimension\n",
    "as the input) that the LLM automatically adjusts during training if it is determined that\n",
    "doing so would improve the model's performance on its training task. \n",
    "- This allows the model\n",
    "to learn appropriate scaling and shifting that best suit the data it is processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d3940-241f-4974-85b9-e0a31b6af883",
   "metadata": {},
   "source": [
    "- Note\n",
    "- In our variance calculation method, we have opted for an implementation detail by\n",
    "setting unbiased=False. \n",
    "\n",
    "- For those curious about what this means, in the variance\n",
    "calculation, we divide by the number of inputs n in the variance formula. \n",
    "\n",
    "- This approach does not apply Bessel's correction, which typically uses n-1 instead of n in\n",
    "the denominator to adjust for bias in sample variance estimation. \n",
    "\n",
    "- This decision results in a so-called biased estimate of the variance. \n",
    "\n",
    "- For large-scale language\n",
    "models (LLMs), where the embedding dimension n is significantly large, the\n",
    "difference between using n and n-1 is practically negligible. \n",
    "\n",
    "- We chose this approach to ensure compatibility with the GPT-2 model's normalization layers and because it\n",
    "reflects TensorFlow's default behavior, which was used to implement the original GPT2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0170d7e7-bf0b-4d73-976f-7d498bf1f06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafd200-9135-446b-859d-6b2256f705a5",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 3: FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d32f1d-2dcb-4702-9672-159cce9e571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0/torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x,3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba04dc9-c57d-4fe9-bf03-94d92a586f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b83a30-bb90-48cb-be33-7f052f940e1e",
   "metadata": {},
   "source": [
    "- The smoothness of GELU, as shown in the above figure, can lead to better optimization properties\n",
    "during training, as it allows for more nuanced adjustments to the model's parameters. \n",
    "\n",
    "- In contrast, ReLU has a sharp corner at zero, which can sometimes make optimization harder,\n",
    "especially in networks that are very deep or have complex architectures. \n",
    "\n",
    "- Moreover, unlike RELU, which outputs zero for any negative input, GELU allows for a small, non-zero output\n",
    "for negative values. \n",
    "\n",
    "- This characteristic means that during the training process, neurons that\n",
    "receive negative input can still contribute to the learning process, albeit to a lesser extent\n",
    "than positive inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c249de12-d6c5-4035-947e-d1e57c36ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54dce449-d300-48c6-b09c-292ac383a0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0321a4-85a5-47d6-9d06-50df310af0f5",
   "metadata": {},
   "source": [
    "- As we can see in the preceding code, the FeedForward module is a small neural network\n",
    "consisting of two Linear layers and a GELU activation function. \n",
    "\n",
    "- In the 124 million parameter GPT model, it receives the input batches with tokens that have an embedding\n",
    "size of 768 each via the GPT_CONFIG_124M dictionary where GPT_CONFIG_124M[\"emb_dim\"]\n",
    "= 768.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d582439-afb6-480d-a686-d30ee8c1fb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676722d-9393-4ec4-af91-cff3b440c9c8",
   "metadata": {},
   "source": [
    "- The FeedForward module we implemented in this section plays a crucial role in enhancing\n",
    "the model's ability to learn from and generalize the data. \n",
    "\n",
    "- Although the input and output dimensions of this module are the same, it internally expands the embedding dimension\n",
    "into a higher-dimensional space through the first linear layer.\n",
    "\n",
    "- This expansion is followed by a non-linear GELU activation, and then a contraction back to\n",
    "the original dimension with the second linear transformation. \n",
    "\n",
    "- Such a design allows for the\n",
    "exploration of a richer representation space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9712a5-db68-41a3-bfd8-77652942e7e2",
   "metadata": {},
   "source": [
    "- Moreover, the uniformity in input and output dimensions simplifies the architecture by\n",
    "enabling the stacking of multiple layers, as we will do later, without the need to adjust\n",
    "dimensions between them, thus making the model more scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c11b15-77aa-4c9f-b886-b7bda51a04f0",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dab6d968-0bf5-4431-a365-fec5cee91a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())]\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "              # compute the output of the current layer\n",
    "              layer_output = layer(x)\n",
    "              # check if shortcut can be applied\n",
    "              if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                  x = x + layer_output\n",
    "              else: \n",
    "                  x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2212e0b4-ce22-4d81-804d-bcbb27370cea",
   "metadata": {},
   "source": [
    "- The code implements a deep neural network with 5 layers, each consisting of a Linear\n",
    "layer and a GELU activation function. \n",
    "- In the forward pass, we iteratively pass the input\n",
    "through the layers and optionally add the shortcut connections  if\n",
    "the self.use_shortcut attribute is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "658d5e31-89f9-4068-8cff-e927abf995fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without shortcut connections\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39a74bd4-e32a-431d-894a-9e348a8e796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that computes the gradients in the model's backward pass\n",
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04a7b7-7741-4aa7-a62f-703a16fad916",
   "metadata": {},
   "source": [
    "- In the preceding code, we specify a loss function that computes how close the model output\n",
    "and a user-specified target (here, for simplicity, the value 0) are. \n",
    "- Then, when calling loss.backward(), PyTorch computes the loss gradient for each layer in the model. \n",
    "- We can iterate through the weight parameters via model.named_parameters(). \n",
    "- Suppose we have a 3×3 weight parameter matrix for a given layer. \n",
    "In that case, this layer will have 3×3 gradient values, and we print the mean absolute gradient of these 3×3 gradient values to\n",
    "obtain a single gradient value per layer to compare the gradients between layers more\n",
    "easily.\n",
    "- In short, the .backward() method is a convenient method in PyTorch that computes loss\n",
    "gradients, which are required during model training, without implementing the math for the\n",
    "gradient calculation ourselves, thereby making working with deep neural networks much\n",
    "more accessible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "366d0b80-c572-49ed-8da4-c0a73524a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5977aa0-539f-4e50-8267-1f4acca4b27c",
   "metadata": {},
   "source": [
    "- As we can see based on the output of the print_gradients function, the gradients become\n",
    "smaller as we progress from the last layer (layers.4) to the first layer (layers.0), which\n",
    "is a phenomenon called the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53524657-4ab1-477e-a7d3-87f83a2492a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015b8ab-b483-4ecc-81b4-12ceb60eab0d",
   "metadata": {},
   "source": [
    "- As we can see, based on the output, the last layer (layers.4) still has a larger gradient\n",
    "than the other layers. \n",
    "- However, the gradient value stabilizes as we progress towards the\n",
    "first layer (layers.0) and doesn't shrink to a vanishingly small value.\n",
    "- In conclusion, shortcut connections are important for overcoming the limitations posed\n",
    "by the vanishing gradient problem in deep neural networks. \n",
    "- Shortcut connections are a core building block of very large models such as LLMs, and they will help facilitate more effective\n",
    "training by ensuring consistent gradient flow across layers when we train the GPT model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102b088-7824-4bb9-a6c7-5b781da7e6e8",
   "metadata": {},
   "source": [
    "# GPT ARCHITECTURE PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f47e7-3564-4e3d-9d3d-ff79996fb104",
   "metadata": {},
   "source": [
    "Step 1: Shortcut connection for attention block\n",
    "\n",
    "Step 2:  Shortcut connection for feed forward block\n",
    "\n",
    "Step 3: Add the original input back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9222a273-6853-45a9-a52b-25b27ad5028c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_length = cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "593a4f97-a02e-4523-a21b-06751e6986d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92857631-4cff-4948-a83a-e72d6585bee2",
   "metadata": {},
   "source": [
    "- The given code defines a TransformerBlock class in PyTorch that includes a multi-head\n",
    "attention mechanism (MultiHeadAttention) and a feed forward network (FeedForward),\n",
    "both configured based on a provided configuration dictionary (cfg), such as\n",
    "GPT_CONFIG_124M\n",
    "- Layer normalization (LayerNorm) is applied before each of these two components, and\n",
    "dropout is applied after them to regularize the model and prevent overfitting. \n",
    "- This is also known as Pre-LayerNorm. \n",
    "- Older architectures, such as the original transformer model,\n",
    "applied layer normalization after the self-attention and feed-forward networks instead,\n",
    "known as Post-LayerNorm, which often leads to worse training dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b73b87-d70d-42c3-8397-0b5f6eee8f52",
   "metadata": {},
   "source": [
    "- The class also implements the forward pass, where each component is followed by a\n",
    "shortcut connection that adds the input of the block to its output. This critical feature helps\n",
    "gradients flow through the network during training and improves the learning of deep\n",
    "models\n",
    "- Using the GPT_CONFIG_124M dictionary we defined earlier, let's instantiate a transformer\n",
    "block and feed it some sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d0db6ff-916b-45b3-9abd-e008975b58e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f912d6-faae-4329-bed4-f2bf2799e7b7",
   "metadata": {},
   "source": [
    "- As we can see from the code output, the transformer block maintains the input dimensions\n",
    "in its output, indicating that the transformer architecture processes sequences of data\n",
    "without altering their shape throughout the network.\n",
    "- The preservation of shape throughout the transformer block architecture is not incidental\n",
    "but a crucial aspect of its design. \n",
    "- This design enables its effective application across a wide\n",
    "range of sequence-to-sequence tasks, where each output vector directly corresponds to an\n",
    "input vector, maintaining a one-to-one relationship.\n",
    "- However, the output is a context vector\n",
    "that encapsulates information from the entire input sequence.\n",
    "- This means that while the physical dimensions of the sequence (length and feature size)\n",
    "remain unchanged as it passes through the transformer block, the content of each output\n",
    "vector is re-encoded to integrate contextual information from across the entire input\n",
    "sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efe167-8257-4138-b140-631e4a2672b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
